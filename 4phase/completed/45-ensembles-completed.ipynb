{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Ensembles:-Bagging\" data-toc-modified-id=\"Ensembles:-Bagging-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Ensembles: Bagging</a></span></li><li><span><a href=\"#Objectives\" data-toc-modified-id=\"Objectives-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Objectives</a></span></li><li><span><a href=\"#Ensemble-Methods\" data-toc-modified-id=\"Ensemble-Methods-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Ensemble Methods</a></span><ul class=\"toc-item\"><li><span><a href=\"#Advantages-&amp;--Disadvantages\" data-toc-modified-id=\"Advantages-&amp;--Disadvantages-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Advantages &amp;  Disadvantages</a></span></li><li><span><a href=\"#Bagging\" data-toc-modified-id=\"Bagging-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Bagging</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Aggregation\" data-toc-modified-id=\"Aggregation-3.2.0.1\"><span class=\"toc-item-num\">3.2.0.1&nbsp;&nbsp;</span>Aggregation</a></span></li><li><span><a href=\"#Three-Varieties,-Three-Levels-of-Randomization\" data-toc-modified-id=\"Three-Varieties,-Three-Levels-of-Randomization-3.2.0.2\"><span class=\"toc-item-num\">3.2.0.2&nbsp;&nbsp;</span>Three Varieties, Three Levels of Randomization</a></span></li></ul></li></ul></li><li><span><a href=\"#Data-Preparation-for-Examples\" data-toc-modified-id=\"Data-Preparation-for-Examples-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Data Preparation for Examples</a></span><ul class=\"toc-item\"><li><span><a href=\"#Defining-Our-Problem\" data-toc-modified-id=\"Defining-Our-Problem-3.3.1\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>Defining Our Problem</a></span></li><li><span><a href=\"#Fix-Columns-with-Missing-Values\" data-toc-modified-id=\"Fix-Columns-with-Missing-Values-3.3.2\"><span class=\"toc-item-num\">3.3.2&nbsp;&nbsp;</span>Fix Columns with Missing Values</a></span></li></ul></li><li><span><a href=\"#Averaging\" data-toc-modified-id=\"Averaging-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Averaging</a></span><ul class=\"toc-item\"><li><span><a href=\"#Model-1---Logistic-Regression\" data-toc-modified-id=\"Model-1---Logistic-Regression-3.4.1\"><span class=\"toc-item-num\">3.4.1&nbsp;&nbsp;</span>Model 1 - Logistic Regression</a></span></li><li><span><a href=\"#Model-2---KNN\" data-toc-modified-id=\"Model-2---KNN-3.4.2\"><span class=\"toc-item-num\">3.4.2&nbsp;&nbsp;</span>Model 2 - KNN</a></span></li><li><span><a href=\"#Model-3---Decision-Tree\" data-toc-modified-id=\"Model-3---Decision-Tree-3.4.3\"><span class=\"toc-item-num\">3.4.3&nbsp;&nbsp;</span>Model 3 - Decision Tree</a></span></li><li><span><a href=\"#Averaging-the-Models\" data-toc-modified-id=\"Averaging-the-Models-3.4.4\"><span class=\"toc-item-num\">3.4.4&nbsp;&nbsp;</span>Averaging the Models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Building-a-VotingClassifier\" data-toc-modified-id=\"Building-a-VotingClassifier-3.4.4.1\"><span class=\"toc-item-num\">3.4.4.1&nbsp;&nbsp;</span>Building a <code>VotingClassifier</code></a></span></li><li><span><a href=\"#Weighted-Averaging-with-the-VotingClassifier\" data-toc-modified-id=\"Weighted-Averaging-with-the-VotingClassifier-3.4.4.2\"><span class=\"toc-item-num\">3.4.4.2&nbsp;&nbsp;</span>Weighted Averaging with the <code>VotingClassifier</code></a></span></li></ul></li></ul></li><li><span><a href=\"#Bagging\" data-toc-modified-id=\"Bagging-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Bagging</a></span><ul class=\"toc-item\"><li><span><a href=\"#Bagging-Algorithm\" data-toc-modified-id=\"Bagging-Algorithm-3.5.1\"><span class=\"toc-item-num\">3.5.1&nbsp;&nbsp;</span>Bagging Algorithm</a></span></li><li><span><a href=\"#Bagging-by-Hand\" data-toc-modified-id=\"Bagging-by-Hand-3.5.2\"><span class=\"toc-item-num\">3.5.2&nbsp;&nbsp;</span>Bagging by Hand</a></span></li><li><span><a href=\"#Bagging-with-sklearn\" data-toc-modified-id=\"Bagging-with-sklearn-3.5.3\"><span class=\"toc-item-num\">3.5.3&nbsp;&nbsp;</span>Bagging with <code>sklearn</code></a></span></li><li><span><a href=\"#Fitting-a-Random-Forest\" data-toc-modified-id=\"Fitting-a-Random-Forest-3.5.4\"><span class=\"toc-item-num\">3.5.4&nbsp;&nbsp;</span>Fitting a Random Forest</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-Goods-&amp;-The-Bads\" data-toc-modified-id=\"The-Goods-&amp;-The-Bads-3.5.4.1\"><span class=\"toc-item-num\">3.5.4.1&nbsp;&nbsp;</span>The Goods &amp; The Bads</a></span></li><li><span><a href=\"#Breed-a-Variety-of-Trees\" data-toc-modified-id=\"Breed-a-Variety-of-Trees-3.5.4.2\"><span class=\"toc-item-num\">3.5.4.2&nbsp;&nbsp;</span>Breed a Variety of Trees</a></span></li><li><span><a href=\"#Steps:\" data-toc-modified-id=\"Steps:-3.5.4.3\"><span class=\"toc-item-num\">3.5.4.3&nbsp;&nbsp;</span>Steps:</a></span></li></ul></li><li><span><a href=\"#Random-Forest-by-Hand\" data-toc-modified-id=\"Random-Forest-by-Hand-3.5.5\"><span class=\"toc-item-num\">3.5.5&nbsp;&nbsp;</span>Random Forest by Hand</a></span></li><li><span><a href=\"#Random-Forest-with-sklearn\" data-toc-modified-id=\"Random-Forest-with-sklearn-3.5.6\"><span class=\"toc-item-num\">3.5.6&nbsp;&nbsp;</span>Random Forest with <code>sklearn</code></a></span></li><li><span><a href=\"#Cool-Features-of-Random-Forests\" data-toc-modified-id=\"Cool-Features-of-Random-Forests-3.5.7\"><span class=\"toc-item-num\">3.5.7&nbsp;&nbsp;</span>Cool Features of Random Forests</a></span><ul class=\"toc-item\"><li><span><a href=\"#Investigate-Your-Forest-ðŸŒ²ðŸŒ²ðŸ‘€ðŸŒ²ðŸŒ²\" data-toc-modified-id=\"Investigate-Your-Forest-ðŸŒ²ðŸŒ²ðŸ‘€ðŸŒ²ðŸŒ²-3.5.7.1\"><span class=\"toc-item-num\">3.5.7.1&nbsp;&nbsp;</span>Investigate Your Forest ðŸŒ²ðŸŒ²ðŸ‘€ðŸŒ²ðŸŒ²</a></span></li><li><span><a href=\"#Feature-Importance\" data-toc-modified-id=\"Feature-Importance-3.5.7.2\"><span class=\"toc-item-num\">3.5.7.2&nbsp;&nbsp;</span>Feature Importance</a></span></li></ul></li><li><span><a href=\"#Extremely-Randomized-Trees-(Extra-Trees)\" data-toc-modified-id=\"Extremely-Randomized-Trees-(Extra-Trees)-3.5.8\"><span class=\"toc-item-num\">3.5.8&nbsp;&nbsp;</span>Extremely Randomized Trees (Extra Trees)</a></span></li></ul></li></ul></li><li><span><a href=\"#Level-Up:-Stacking\" data-toc-modified-id=\"Level-Up:-Stacking-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Level Up: Stacking</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Meta-Classifier/Meta-Regressor\" data-toc-modified-id=\"Meta-Classifier/Meta-Regressor-4.0.0.1\"><span class=\"toc-item-num\">4.0.0.1&nbsp;&nbsp;</span>Meta-Classifier/Meta-Regressor</a></span></li></ul></li></ul></li><li><span><a href=\"#Initial-Data-Prep\" data-toc-modified-id=\"Initial-Data-Prep-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Initial Data Prep</a></span></li><li><span><a href=\"#Splitting\" data-toc-modified-id=\"Splitting-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Splitting</a></span></li><li><span><a href=\"#Setting-Up-a-Pipeline\" data-toc-modified-id=\"Setting-Up-a-Pipeline-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Setting Up a Pipeline</a></span></li><li><span><a href=\"#Setting-Up-a-Stack\" data-toc-modified-id=\"Setting-Up-a-Stack-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Setting Up a Stack</a></span></li><li><span><a href=\"#Comparison-with-Base-Estimators\" data-toc-modified-id=\"Comparison-with-Base-Estimators-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Comparison with Base Estimators</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembles: Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:00:47.935315Z",
     "start_time": "2023-10-11T17:00:46.000315Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xlrd\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, \\\n",
    "ExtraTreesClassifier, VotingClassifier, StackingRegressor\n",
    "\n",
    "from sklearn.metrics import r2_score, accuracy_score\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use `sklearn` to build voting models\n",
    "- Describe the algorithm of bagging\n",
    "- Describe the differences among simple bagging, random forest, and extra trees algorithms\n",
    "- Implement bagging models in `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because many heads are better than one!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=50% src='images/captain_planet.jpg'/>\n",
    "\n",
    "> \"With our powers combined...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These models tend to perform very well and generalize well!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advantages &  Disadvantages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Decreases variance â†’ Less overfitting!\n",
    "- More complexity (you have to train each model or part of model)\n",
    "- Tends to take up more space (have to keep each model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/bag_of_marbles.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Many models naturally overfit\n",
    "- Randomization â†’ New models\n",
    "- New models overfit in different ways\n",
    "- Aggregation â†’ Smooth over different ways of overfitting to reduce variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Low variance since it averages out quirks individual trees might've learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **B**ootstrap **AGG**regating\n",
    "- Algorithm to repeat many times:\n",
    "    + Create a sample from your data\n",
    "    + Train a model (e.g. a decision tree) on that sample\n",
    "- Final model comes by averaging over those many models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Three Varieties, Three Levels of Randomization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Simple Bag**: Train each model on random sample\n",
    "2. **Random Forest**: Choose a random set of features at each decision point\n",
    "3. **Extra Trees**: Choose a path at random!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation for Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let's prepare some data to do some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:05:10.411529Z",
     "start_time": "2023-10-11T17:05:10.364527Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>cubicinches</th>\n",
       "      <th>hp</th>\n",
       "      <th>weightlbs</th>\n",
       "      <th>time-to-60</th>\n",
       "      <th>year</th>\n",
       "      <th>brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350</td>\n",
       "      <td>165</td>\n",
       "      <td>4209</td>\n",
       "      <td>12</td>\n",
       "      <td>1972</td>\n",
       "      <td>US.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.9</td>\n",
       "      <td>4</td>\n",
       "      <td>89</td>\n",
       "      <td>71</td>\n",
       "      <td>1925</td>\n",
       "      <td>14</td>\n",
       "      <td>1980</td>\n",
       "      <td>Europe.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302</td>\n",
       "      <td>140</td>\n",
       "      <td>3449</td>\n",
       "      <td>11</td>\n",
       "      <td>1971</td>\n",
       "      <td>US.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>400</td>\n",
       "      <td>150</td>\n",
       "      <td>3761</td>\n",
       "      <td>10</td>\n",
       "      <td>1971</td>\n",
       "      <td>US.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.5</td>\n",
       "      <td>4</td>\n",
       "      <td>98</td>\n",
       "      <td>63</td>\n",
       "      <td>2051</td>\n",
       "      <td>17</td>\n",
       "      <td>1978</td>\n",
       "      <td>US.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg   cylinders  cubicinches   hp  weightlbs   time-to-60   year     brand\n",
       "0  14.0           8          350  165       4209           12   1972       US.\n",
       "1  31.9           4           89   71       1925           14   1980   Europe.\n",
       "2  17.0           8          302  140       3449           11   1971       US.\n",
       "3  15.0           8          400  150       3761           10   1971       US.\n",
       "4  30.5           4           98   63       2051           17   1978       US."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/cars.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:06:03.792695Z",
     "start_time": "2023-10-11T17:06:03.774695Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 261 entries, 0 to 260\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   mpg           261 non-null    float64\n",
      " 1    cylinders    261 non-null    int64  \n",
      " 2    cubicinches  261 non-null    object \n",
      " 3    hp           261 non-null    int64  \n",
      " 4    weightlbs    261 non-null    object \n",
      " 5    time-to-60   261 non-null    int64  \n",
      " 6    year         261 non-null    int64  \n",
      " 7    brand        261 non-null    object \n",
      "dtypes: float64(1), int64(4), object(3)\n",
      "memory usage: 16.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:06:12.200229Z",
     "start_time": "2023-10-11T17:06:12.181232Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:06:21.220229Z",
     "start_time": "2023-10-11T17:06:21.212229Z"
    }
   },
   "outputs": [],
   "source": [
    "df.columns = [x.replace(' ','').lower() for x in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:06:21.577230Z",
     "start_time": "2023-10-11T17:06:21.561230Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 261 entries, 0 to 260\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   mpg          261 non-null    float64\n",
      " 1   cylinders    261 non-null    int64  \n",
      " 2   cubicinches  261 non-null    object \n",
      " 3   hp           261 non-null    int64  \n",
      " 4   weightlbs    261 non-null    object \n",
      " 5   time-to-60   261 non-null    int64  \n",
      " 6   year         261 non-null    int64  \n",
      " 7   brand        261 non-null    object \n",
      "dtypes: float64(1), int64(4), object(3)\n",
      "memory usage: 16.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Our Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can predict whether a car is American or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:06:35.815241Z",
     "start_time": "2023-10-11T17:06:35.808239Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " US.        162\n",
       " Japan.      51\n",
       " Europe.     48\n",
       "Name: brand, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['brand'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:06:46.677564Z",
     "start_time": "2023-10-11T17:06:46.662563Z"
    }
   },
   "outputs": [],
   "source": [
    "df['brand'] = df.brand.map(lambda x: x.strip().replace('.','').lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:06:47.592563Z",
     "start_time": "2023-10-11T17:06:47.578563Z"
    }
   },
   "outputs": [],
   "source": [
    "df['target'] = df['brand'] == 'us'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:06:49.178647Z",
     "start_time": "2023-10-11T17:06:49.156633Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>cubicinches</th>\n",
       "      <th>hp</th>\n",
       "      <th>weightlbs</th>\n",
       "      <th>time-to-60</th>\n",
       "      <th>year</th>\n",
       "      <th>brand</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350</td>\n",
       "      <td>165</td>\n",
       "      <td>4209</td>\n",
       "      <td>12</td>\n",
       "      <td>1972</td>\n",
       "      <td>us</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.9</td>\n",
       "      <td>4</td>\n",
       "      <td>89</td>\n",
       "      <td>71</td>\n",
       "      <td>1925</td>\n",
       "      <td>14</td>\n",
       "      <td>1980</td>\n",
       "      <td>europe</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302</td>\n",
       "      <td>140</td>\n",
       "      <td>3449</td>\n",
       "      <td>11</td>\n",
       "      <td>1971</td>\n",
       "      <td>us</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>400</td>\n",
       "      <td>150</td>\n",
       "      <td>3761</td>\n",
       "      <td>10</td>\n",
       "      <td>1971</td>\n",
       "      <td>us</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.5</td>\n",
       "      <td>4</td>\n",
       "      <td>98</td>\n",
       "      <td>63</td>\n",
       "      <td>2051</td>\n",
       "      <td>17</td>\n",
       "      <td>1978</td>\n",
       "      <td>us</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders cubicinches   hp weightlbs  time-to-60  year   brand  \\\n",
       "0  14.0          8         350  165      4209          12  1972      us   \n",
       "1  31.9          4          89   71      1925          14  1980  europe   \n",
       "2  17.0          8         302  140      3449          11  1971      us   \n",
       "3  15.0          8         400  150      3761          10  1971      us   \n",
       "4  30.5          4          98   63      2051          17  1978      us   \n",
       "\n",
       "   target  \n",
       "0    True  \n",
       "1   False  \n",
       "2    True  \n",
       "3    True  \n",
       "4    True  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix Columns with Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:07:03.639250Z",
     "start_time": "2023-10-11T17:07:03.619242Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>cubicinches</th>\n",
       "      <th>hp</th>\n",
       "      <th>weightlbs</th>\n",
       "      <th>time-to-60</th>\n",
       "      <th>year</th>\n",
       "      <th>brand</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>16.0</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>105</td>\n",
       "      <td>3897</td>\n",
       "      <td>19</td>\n",
       "      <td>1976</td>\n",
       "      <td>us</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>19.8</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>85</td>\n",
       "      <td>2990</td>\n",
       "      <td>18</td>\n",
       "      <td>1980</td>\n",
       "      <td>us</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg  cylinders cubicinches   hp weightlbs  time-to-60  year brand  \\\n",
       "40   16.0          6              105      3897          19  1976    us   \n",
       "180  19.8          6               85      2990          18  1980    us   \n",
       "\n",
       "     target  \n",
       "40     True  \n",
       "180    True  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert cubicinches and weightlbs to numbers\n",
    "df[df['cubicinches'] == ' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:07:13.971242Z",
     "start_time": "2023-10-11T17:07:13.956243Z"
    }
   },
   "outputs": [],
   "source": [
    "df['cubicinches'] = df['cubicinches'].map(lambda x: np.nan if x == ' ' else int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:07:14.634241Z",
     "start_time": "2023-10-11T17:07:14.613243Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>cubicinches</th>\n",
       "      <th>hp</th>\n",
       "      <th>weightlbs</th>\n",
       "      <th>time-to-60</th>\n",
       "      <th>year</th>\n",
       "      <th>brand</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>19.1</td>\n",
       "      <td>6</td>\n",
       "      <td>225.0</td>\n",
       "      <td>90</td>\n",
       "      <td></td>\n",
       "      <td>19</td>\n",
       "      <td>1981</td>\n",
       "      <td>us</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>199.0</td>\n",
       "      <td>90</td>\n",
       "      <td></td>\n",
       "      <td>15</td>\n",
       "      <td>1971</td>\n",
       "      <td>us</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>29.0</td>\n",
       "      <td>4</td>\n",
       "      <td>68.0</td>\n",
       "      <td>49</td>\n",
       "      <td></td>\n",
       "      <td>20</td>\n",
       "      <td>1974</td>\n",
       "      <td>europe</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg  cylinders  cubicinches  hp weightlbs  time-to-60  year   brand  \\\n",
       "14   19.1          6        225.0  90                    19  1981      us   \n",
       "33   21.0          6        199.0  90                    15  1971      us   \n",
       "172  29.0          4         68.0  49                    20  1974  europe   \n",
       "\n",
       "     target  \n",
       "14     True  \n",
       "33     True  \n",
       "172   False  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['weightlbs'] == ' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:07:15.264241Z",
     "start_time": "2023-10-11T17:07:15.245242Z"
    }
   },
   "outputs": [],
   "source": [
    "df['weightlbs'] = df['weightlbs'].map(lambda x: np.nan if x == ' ' else int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:08:09.932242Z",
     "start_time": "2023-10-11T17:08:09.920243Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(['target', 'brand'], axis=1), df['target'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:08:20.327243Z",
     "start_time": "2023-10-11T17:08:20.306245Z"
    }
   },
   "outputs": [],
   "source": [
    "si = SimpleImputer()\n",
    "\n",
    "si.fit(X_train)\n",
    "\n",
    "X_tr_im = si.transform(X_train)\n",
    "X_te_im = si.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:13:55.652244Z",
     "start_time": "2023-10-11T17:13:55.644242Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_scores(estimator, X_train, X_test, y_train, y_test):\n",
    "    cv_scores = cross_val_score(estimator, X_train,y_train)\n",
    "    print(f'Cross Val: {cv_scores}')\n",
    "    print(f'Median: {np.median(cv_scores)}')\n",
    "    print(f'Mean: {np.mean(cv_scores)}')\n",
    "    print(f'Test: {estimator.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Each model uses the same data to train and then we \"vote\" to make a prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:09:38.169239Z",
     "start_time": "2023-10-11T17:09:38.112243Z"
    }
   },
   "outputs": [],
   "source": [
    "# lr\n",
    "\n",
    "lr = LogisticRegression(random_state=42, max_iter=1000).fit(X_tr_im, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:14:23.350243Z",
     "start_time": "2023-10-11T17:14:23.151245Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val: [0.84615385 0.92307692 0.76923077 0.94871795 0.79487179]\n",
      "Median: 0.8461538461538461\n",
      "Mean: 0.8564102564102564\n",
      "Test: 0.8939393939393939\n"
     ]
    }
   ],
   "source": [
    "print_scores(lr,X_tr_im, X_te_im, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 - KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:10:09.346243Z",
     "start_time": "2023-10-11T17:10:09.328242Z"
    }
   },
   "outputs": [],
   "source": [
    "# knn\n",
    "\n",
    "knn = KNeighborsClassifier(3).fit(X_tr_im, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:14:29.925244Z",
     "start_time": "2023-10-11T17:14:29.883244Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val: [0.76923077 0.82051282 0.79487179 0.76923077 0.76923077]\n",
      "Median: 0.7692307692307693\n",
      "Mean: 0.7846153846153846\n",
      "Test: 0.7878787878787878\n"
     ]
    }
   ],
   "source": [
    "print_scores(knn,X_tr_im, X_te_im, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 - Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:10:47.493244Z",
     "start_time": "2023-10-11T17:10:47.484243Z"
    }
   },
   "outputs": [],
   "source": [
    "# dt\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42).fit(X_tr_im, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:14:36.395243Z",
     "start_time": "2023-10-11T17:14:36.359241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val: [0.8974359  0.87179487 0.82051282 0.8974359  0.79487179]\n",
      "Median: 0.8717948717948718\n",
      "Mean: 0.8564102564102564\n",
      "Test: 0.7878787878787878\n"
     ]
    }
   ],
   "source": [
    "print_scores(dt,X_tr_im, X_te_im, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaging the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a `VotingClassifier`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Of course there's a Scikit-Learn class for that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:12:39.155244Z",
     "start_time": "2023-10-11T17:12:39.149243Z"
    }
   },
   "outputs": [],
   "source": [
    "# voting!\n",
    "\n",
    "avg = VotingClassifier(estimators=[\n",
    "    ('lr',lr),\n",
    "    ('knn', knn),\n",
    "    ('dt',dt)\n",
    "], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:12:49.496243Z",
     "start_time": "2023-10-11T17:12:49.439243Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Voting] ....................... (1 of 3) Processing lr, total=   0.0s\n",
      "[Voting] ...................... (2 of 3) Processing knn, total=   0.0s\n",
      "[Voting] ....................... (3 of 3) Processing dt, total=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr',\n",
       "                              LogisticRegression(max_iter=1000,\n",
       "                                                 random_state=42)),\n",
       "                             ('knn', KNeighborsClassifier(n_neighbors=3)),\n",
       "                             ('dt', DecisionTreeClassifier(random_state=42))],\n",
       "                 verbose=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg.fit(X_tr_im, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:14:00.466241Z",
     "start_time": "2023-10-11T17:14:00.223242Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Voting] ....................... (1 of 3) Processing lr, total=   0.0s\n",
      "[Voting] ...................... (2 of 3) Processing knn, total=   0.0s\n",
      "[Voting] ....................... (3 of 3) Processing dt, total=   0.0s\n",
      "[Voting] ....................... (1 of 3) Processing lr, total=   0.0s\n",
      "[Voting] ...................... (2 of 3) Processing knn, total=   0.0s\n",
      "[Voting] ....................... (3 of 3) Processing dt, total=   0.0s\n",
      "[Voting] ....................... (1 of 3) Processing lr, total=   0.0s\n",
      "[Voting] ...................... (2 of 3) Processing knn, total=   0.0s\n",
      "[Voting] ....................... (3 of 3) Processing dt, total=   0.0s\n",
      "[Voting] ....................... (1 of 3) Processing lr, total=   0.0s\n",
      "[Voting] ...................... (2 of 3) Processing knn, total=   0.0s\n",
      "[Voting] ....................... (3 of 3) Processing dt, total=   0.0s\n",
      "[Voting] ....................... (1 of 3) Processing lr, total=   0.0s\n",
      "[Voting] ...................... (2 of 3) Processing knn, total=   0.0s\n",
      "[Voting] ....................... (3 of 3) Processing dt, total=   0.0s\n",
      "Cross Val: [0.87179487 0.8974359  0.82051282 0.8974359  0.79487179]\n",
      "Median: 0.8717948717948718\n",
      "Mean: 0.8564102564102564\n",
      "Test: 0.8636363636363636\n"
     ]
    }
   ],
   "source": [
    "print_scores(avg,X_tr_im, X_te_im, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weighted Averaging with the `VotingClassifier`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Even if the vote is 50-50, you'd probably side with the \"smart\" ones more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This meta-estimator is not as good as one of our base estimators, so in this case the averaging did not work very well. Realizing that the logistic regression is performing better than the decision tree and the k-nearest-neighbors model, however, we might decide to build a meta-estimator by calculating a **weighted average** of the base estimators' predictions. And we can weight, or bias, this estimator in favor of the best-performing base estimator. Suppose we weight the logistic regression 50%, the knn model 25%, and the logistic regression 25%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:15:50.324245Z",
     "start_time": "2023-10-11T17:15:50.272241Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr',\n",
       "                              LogisticRegression(max_iter=1000,\n",
       "                                                 random_state=42)),\n",
       "                             ('knn', KNeighborsClassifier(n_neighbors=3)),\n",
       "                             ('dt', DecisionTreeClassifier(random_state=42))],\n",
       "                 weights=[0.5, 0.25, 0.25])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_avg = VotingClassifier(estimators=[\n",
    "    ('lr', lr),\n",
    "    ('knn', knn),\n",
    "    ('dt', dt)],\n",
    "    weights=[0.5, 0.25, 0.25])\n",
    "w_avg.fit(X_tr_im, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:15:56.812242Z",
     "start_time": "2023-10-11T17:15:56.575244Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val: [0.87179487 0.92307692 0.79487179 0.92307692 0.79487179]\n",
      "Median: 0.8717948717948718\n",
      "Mean: 0.8615384615384615\n",
      "Test: 0.9242424242424242\n"
     ]
    }
   ],
   "source": [
    "print_scores(w_avg,X_tr_im, X_te_im, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single decision tree will often overfit your training data. Let's see if we have evidence of that in the current case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:17:51.666243Z",
     "start_time": "2023-10-11T17:17:51.644244Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val: [0.8974359  0.87179487 0.82051282 0.8974359  0.79487179]\n",
      "Median: 0.8717948717948718\n",
      "Mean: 0.8564102564102564\n",
      "Test: 0.7878787878787878\n"
     ]
    }
   ],
   "source": [
    "# tree train\n",
    "\n",
    "print_scores(dt,X_tr_im, X_te_im, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>ðŸ§  Knowledge Check</b>: What is this score? And why is it equal to 1?</summary>\n",
    "    <br/>\n",
    "    <quote>\n",
    "    This perfect score on the training data is already evidence of model overfitting. There are steps one can take to help with this, like limiting the \"depth\" of the nodes. And of course we can use cross-validation to get a more honest estimate of model quality.\n",
    "    </quote>\n",
    "</details>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But it's often better to do something else: Plant another tree!\n",
    "\n",
    "Of course, if a second tree is going to be of any value, it has to be *different from* the first. Here's a good algorithm for achieving that:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Take a sample of your X_train and fit a decision tree to it.\n",
    "- Replace the first batch of data and repeat.\n",
    "- When you've got as many trees as you like, make use of all your individual trees' predictions to come up with some holistic prediction. \n",
    "    - (Most obviously, we could take the average of our predictions, but there are other methods we might try.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Because we're resampling our data with replacement, we're *bootstrapping*.\n",
    "* Because we're making use of our many samples' predictions, we're *aggregating*.\n",
    "* Because we're bootstrapping and aggregating all in the same algorithm, we're *bagging*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging by Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:18:54.760876Z",
     "start_time": "2023-10-11T17:18:54.748878Z"
    }
   },
   "outputs": [],
   "source": [
    "def simple_bagger(X_train, y_train, X_test=None, n_trees=10):\n",
    "    \"\"\"\n",
    "    This function will build `n_trees`-many decision tree classifiers\n",
    "    with random_state=42 on subsets of X_train (and y_train), returning\n",
    "    average predictions (averaging on the .predict_proba() method of the\n",
    "    decision trees as opposed to the .predict() method) on X_test. If X_test\n",
    "    is not specified, the function will predict on X_train.\n",
    "    \"\"\"\n",
    "    \n",
    "    if X_test is None:\n",
    "        X_test = X_train\n",
    "        \n",
    "    y_train = y_train.values.reshape(-1, 1)\n",
    "    data = np.hstack((X_train, y_train))\n",
    "    \n",
    "    num_recs = y_train.shape[0]\n",
    "    \n",
    "    preds = []\n",
    "    \n",
    "    for _ in range(n_trees):\n",
    "        \n",
    "        # Train on 10% of the training data\n",
    "        subset = np.random.choice(num_recs, size=num_recs//10)\n",
    "            # Note that there is still randomness here!\n",
    "        training = data[subset, :]\n",
    "        ct = DecisionTreeClassifier(random_state=42)\n",
    "        ct.fit(training[:, :-1], training[:, -1])\n",
    "        preds.append(ct.predict_proba(X_test))\n",
    "\n",
    "    return np.mean(preds, axis=0).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:19:46.176877Z",
     "start_time": "2023-10-11T17:19:46.161878Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test it\n",
    "\n",
    "simple_bagger(X_tr_im, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging with `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:21:57.251228Z",
     "start_time": "2023-10-11T17:21:55.267231Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instatiate a BaggingRegessor\n",
    "# Note the base esimator is by default a decision tree\n",
    "\n",
    "bag = BaggingClassifier(n_estimators=1000, random_state=42).fit(X_tr_im, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:22:30.061007Z",
     "start_time": "2023-10-11T17:22:30.028008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val: [0.8974359  0.87179487 0.82051282 0.8974359  0.79487179]\n",
      "Median: 0.8717948717948718\n",
      "Mean: 0.8564102564102564\n",
      "Test: 0.7878787878787878\n"
     ]
    }
   ],
   "source": [
    "print_scores(dt,X_tr_im, X_te_im, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:22:19.277009Z",
     "start_time": "2023-10-11T17:22:09.529500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val: [0.8974359  0.92307692 0.87179487 0.92307692 0.76923077]\n",
      "Median: 0.8974358974358975\n",
      "Mean: 0.876923076923077\n",
      "Test: 0.8484848484848485\n"
     ]
    }
   ],
   "source": [
    "# Print Scores\n",
    "print_scores(bag,X_tr_im, X_te_im, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Goods & The Bads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Goods**\n",
    "\n",
    "- Super friend! \n",
    "- High performance \n",
    "    + low variance\n",
    "- Transparent\n",
    "    + inherited from Decision Trees\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Bads**\n",
    "\n",
    "- We got so many trees to plant...\n",
    "- Computationally expensive\n",
    "- Memory\n",
    "    + all trees stored in memory\n",
    "    + think back to k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Breed a Variety of Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add an extra layer of randomization: Instead of using *all* the features of my model to optimize a branch at each node, I'll just choose a subset of my features.\n",
    "\n",
    "That's the essence of a random forest model. Note that there are now **two** levels of random sampling happening: To build a new tree, I'll be taking only some of my data points; and at any branching point in a tree, I'll be using only some of my features to determine the split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Save a portion of data for validation (**out-of-bag**), the rest for training (**bag**)\n",
    "2. The data for training (**bag**) is then split up by randomly selecting predictors\n",
    "3. Grow/train your tree with the training data using just those features\n",
    "4. Use our validation set (**out-of-bag**), take out the columns used in our tree from the previous step, and predict using the tree & this *out-of-bag* data\n",
    "5. Compare on how well the tree did *out-of-bag error*\n",
    "6. Repeat to make new trees and use the result to \"vote\" for the final decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest by Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:31:17.803738Z",
     "start_time": "2023-10-11T17:31:17.781741Z"
    }
   },
   "outputs": [],
   "source": [
    "def bagger(X_train, y_train, X_test=None, n_trees=10, random_forest=False):\n",
    "    \"\"\"\n",
    "    This function will build `n_trees`-many decision tree classifiers\n",
    "    with random_state=42 on subsets of X_train (and y_train), returning\n",
    "    average predictions (averaging on the .predict_proba() method of the\n",
    "    decision trees as opposed to the .predict() method) on X_test. If X_test\n",
    "    is not specified, the function will predict on X_train. If `random_forest`\n",
    "    is set to True, a number of features equal to sqrt(n_features) will be\n",
    "    used to build each tree.\n",
    "    \"\"\"\n",
    "\n",
    "    if X_test is None:\n",
    "        X_test = X_train\n",
    "\n",
    "    y_train = y_train.values.reshape(-1, 1)\n",
    "    data = np.hstack((X_train, y_train))\n",
    "    \n",
    "    num_recs = X_train.shape[0]\n",
    "    num_feats = X_train.shape[1]\n",
    "    preds = []\n",
    "    \n",
    "    for _ in range(n_trees):\n",
    "        \n",
    "        # Train on 10% of the training data\n",
    "        subset = np.random.choice(num_recs, size=num_recs//10).reshape(-1, 1)\n",
    "        \n",
    "        # For random forest, choose only some features\n",
    "        if random_forest == True:\n",
    "            subfeatures = np.random.choice(num_feats, size=int(np.sqrt(num_feats)))\n",
    "        else:\n",
    "            subfeatures = np.arange(num_feats)\n",
    "            \n",
    "        subfeatures_y = np.append(subfeatures, -1).reshape(1, -1)\n",
    "        training = data[subset, subfeatures_y]\n",
    "        \n",
    "        ct = DecisionTreeClassifier(random_state=42)\n",
    "        ct.fit(training[:, :-1], training[:, -1])\n",
    "        \n",
    "        preds.append(ct.predict_proba(X_test[:, subfeatures]))\n",
    "    \n",
    "    return np.mean(preds, axis=0).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:32:07.153740Z",
     "start_time": "2023-10-11T17:32:07.125740Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8484848484848485"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, bagger(X_tr_im, y_train, X_te_im, random_forest=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Here's the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier) on `RandomForestClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:46:39.971358Z",
     "start_time": "2023-10-11T17:46:39.763361Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=100, max_samples=.3, random_state=42, verbose =1).fit(X_tr_im, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:38:00.397929Z",
     "start_time": "2023-10-11T17:38:00.389931Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fit it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:38:00.872929Z",
     "start_time": "2023-10-11T17:38:00.721930Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val: [0.87179487 0.94871795 0.82051282 0.87179487 0.79487179]\n",
      "Median: 0.8717948717948718\n",
      "Mean: 0.8615384615384615\n",
      "Test: 0.8484848484848485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Print scores \n",
    "print_scores(rfc,X_tr_im, X_te_im, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cool Features of Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some extra investigations we can do with random forests since they're built of decision trees.\n",
    "\n",
    "> **NOTE**\n",
    ">\n",
    "> Not all of these are _specific_ to random forests and can be applied to other (ensemble) models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate Your Forest ðŸŒ²ðŸŒ²ðŸ‘€ðŸŒ²ðŸŒ²"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check out our trained estimators after training the ensemble. This isn't necessarily unique to random forests, but since the base model is always a decision tree we can really investigate how the model is working!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:38:03.698935Z",
     "start_time": "2023-10-11T17:38:03.685931Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[DecisionTreeClassifier(max_features='auto', random_state=1608637542),\n",
       " DecisionTreeClassifier(max_features='auto', random_state=1273642419),\n",
       " DecisionTreeClassifier(max_features='auto', random_state=1935803228),\n",
       " DecisionTreeClassifier(max_features='auto', random_state=787846414),\n",
       " DecisionTreeClassifier(max_features='auto', random_state=996406378),\n",
       " DecisionTreeClassifier(max_features='auto', random_state=1201263687),\n",
       " DecisionTreeClassifier(max_features='auto', random_state=423734972),\n",
       " DecisionTreeClassifier(max_features='auto', random_state=415968276),\n",
       " DecisionTreeClassifier(max_features='auto', random_state=670094950),\n",
       " DecisionTreeClassifier(max_features='auto', random_state=1914837113)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_estimators = rfc.estimators_ \n",
    "print(len(model_estimators))\n",
    "model_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:38:45.574929Z",
     "start_time": "2023-10-11T17:38:45.533934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall model's score was 0.848\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_features='auto', random_state=1201263687)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tModel gave score of 0.788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_features='auto', random_state=423734972)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tModel gave score of 0.788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_features='auto', random_state=415968276)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tModel gave score of 0.742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_features='auto', random_state=670094950)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tModel gave score of 0.833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_features='auto', random_state=1914837113)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tModel gave score of 0.606\n"
     ]
    }
   ],
   "source": [
    "print(f'Overall model\\'s score was {rfc.score(X_te_im, y_test):.3f}')\n",
    "print('='*70)\n",
    "\n",
    "for model in model_estimators[-5:]:\n",
    "    display(model)\n",
    "    model_score = model.score(X_te_im, y_test)\n",
    "    print(f'\\tModel gave score of {model_score:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use [`.feature_importances_`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.feature_importances_) property of the trained model to get an idea of what features mattered the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:39:12.383447Z",
     "start_time": "2023-10-11T17:39:12.364449Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12139333, 0.25309926, 0.25967389, 0.07920771, 0.19112582,\n",
       "       0.03596889, 0.0595311 ])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:42:54.308841Z",
     "start_time": "2023-10-11T17:42:54.211843Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999999"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(rfc.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:41:03.322986Z",
     "start_time": "2023-10-11T17:41:03.219987Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mpg': 0.13597180006737605,\n",
       " 'cylinders': 0.09786834710625335,\n",
       " 'cubicinches': 0.3111230964569442,\n",
       " 'hp': 0.12991503403403493,\n",
       " 'weightlbs': 0.1865962815529666,\n",
       " 'time-to-60': 0.06344430764733279,\n",
       " 'year': 0.07508113313509202}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_import = {name: score \n",
    "                   for name, score \n",
    "                       in zip(X_train.columns, rfc.feature_importances_)\n",
    "}\n",
    "feat_import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extremely Randomized Trees (Extra Trees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we might want even one more bit of randomization. Instead of always choosing the *optimal* branching path, we might just choose a branching path at random. If we're doing that, then we've got extremely randomized trees.\n",
    "\n",
    "There are now **three** levels of randomization: sampling of data, sampling of features, and random selection of branching paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:46:04.342358Z",
     "start_time": "2023-10-11T17:46:04.329363Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate an ExtraTreesRegressor\n",
    "\n",
    "\n",
    "xtc = ExtraTreesClassifier(max_samples=.3,bootstrap=True, random_state=42, verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:46:14.393360Z",
     "start_time": "2023-10-11T17:46:14.184367Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=True, max_samples=0.3, random_state=42,\n",
       "                     verbose=1)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtc.fit(X_tr_im, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:46:22.075363Z",
     "start_time": "2023-10-11T17:46:21.330359Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val: [0.87179487 0.92307692 0.84615385 0.84615385 0.79487179]\n",
      "Median: 0.8461538461538461\n",
      "Mean: 0.8564102564102564\n",
      "Test: 0.8484848484848485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Print Scores\n",
    "print_scores(xtc,X_tr_im, X_te_im, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:46:54.133357Z",
     "start_time": "2023-10-11T17:46:53.311358Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val: [0.87179487 0.94871795 0.84615385 0.87179487 0.79487179]\n",
      "Median: 0.8717948717948718\n",
      "Mean: 0.8666666666666666\n",
      "Test: 0.8636363636363636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "print_scores(rfc,X_tr_im, X_te_im, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:47:57.788061Z",
     "start_time": "2023-10-11T17:47:57.770058Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11356273, 0.1526864 , 0.22354343, 0.12840673, 0.19092611,\n",
       "       0.08930346, 0.10157113])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtc.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:48:12.905058Z",
     "start_time": "2023-10-11T17:48:12.872061Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mpg': 0.11356273137745003,\n",
       " 'cylinders': 0.1526864048529622,\n",
       " 'cubicinches': 0.22354343150112288,\n",
       " 'hp': 0.12840672908863887,\n",
       " 'weightlbs': 0.1909261087800282,\n",
       " 'time-to-60': 0.08930346477149975,\n",
       " 'year': 0.10157112962829803}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_import = {name: score \n",
    "                   for name, score \n",
    "                       in zip(X_train.columns, xtc.feature_importances_)\n",
    "}\n",
    "feat_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:48:26.349059Z",
     "start_time": "2023-10-11T17:48:26.323062Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mpg': 0.143609339528514,\n",
       " 'cylinders': 0.11362138678976928,\n",
       " 'cubicinches': 0.29174490390579544,\n",
       " 'hp': 0.11350193639792439,\n",
       " 'weightlbs': 0.19769358621453248,\n",
       " 'time-to-60': 0.059485431111608145,\n",
       " 'year': 0.0803434160518563}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_import = {name: score \n",
    "                   for name, score \n",
    "                       in zip(X_train.columns, rfc.feature_importances_)\n",
    "}\n",
    "feat_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level Up: Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Meta-Classifier/Meta-Regressor\n",
    "\n",
    "- First, we ask several different models to make predictions about the target\n",
    "- Rather than taking a simple average or vote to determine the outcome, feed these results into a final model that makes the prediction based on the other modelsâ€™ predictions\n",
    "- If it seems like we are approaching a neural network...you are correct!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Remember weighted averaging? Stacking is about using DS models to estimate those weights for us. This means we'll have one layer of base estimators and another layer that is \"**trained to optimally combine the model predictions to form a new set of predictions**\". See [this short blog post](https://blogs.sas.com/content/subconsciousmusings/2017/05/18/stacked-ensemble-models-win-data-science-competitions/) for more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:50:21.587603Z",
     "start_time": "2023-10-11T17:50:19.750602Z"
    }
   },
   "outputs": [],
   "source": [
    "wb = xlrd.open_workbook('data/Sales Report.xls',\n",
    "                        logfile=open(os.devnull, 'w'))\n",
    "\n",
    "sales = pd.read_excel(wb)\n",
    "sales = sales.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:50:23.430604Z",
     "start_time": "2023-10-11T17:50:23.385605Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row ID</th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Ship Date</th>\n",
       "      <th>Ship Mode</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>Segment</th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>...</th>\n",
       "      <th>Postal Code</th>\n",
       "      <th>Region</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Sub-Category</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CA-2017-152156</td>\n",
       "      <td>2017-11-08</td>\n",
       "      <td>2017-11-11</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>CG-12520</td>\n",
       "      <td>Claire Gute</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>...</td>\n",
       "      <td>42420.0</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-BO-10001798</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Bookcases</td>\n",
       "      <td>Bush Somerset Collection Bookcase</td>\n",
       "      <td>261.9600</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>41.9136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>CA-2017-152156</td>\n",
       "      <td>2017-11-08</td>\n",
       "      <td>2017-11-11</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>CG-12520</td>\n",
       "      <td>Claire Gute</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>...</td>\n",
       "      <td>42420.0</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-CH-10000454</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Chairs</td>\n",
       "      <td>Hon Deluxe Fabric Upholstered Stacking Chairs,...</td>\n",
       "      <td>731.9400</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>219.5820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>CA-2017-138688</td>\n",
       "      <td>2017-06-12</td>\n",
       "      <td>2017-06-16</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>DV-13045</td>\n",
       "      <td>Darrin Van Huff</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>United States</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>...</td>\n",
       "      <td>90036.0</td>\n",
       "      <td>West</td>\n",
       "      <td>OFF-LA-10000240</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Labels</td>\n",
       "      <td>Self-Adhesive Address Labels for Typewriters b...</td>\n",
       "      <td>14.6200</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.8714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>US-2016-108966</td>\n",
       "      <td>2016-10-11</td>\n",
       "      <td>2016-10-18</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>SO-20335</td>\n",
       "      <td>Sean O'Donnell</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>...</td>\n",
       "      <td>33311.0</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-TA-10000577</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Tables</td>\n",
       "      <td>Bretford CR4500 Series Slim Rectangular Table</td>\n",
       "      <td>957.5775</td>\n",
       "      <td>5</td>\n",
       "      <td>0.45</td>\n",
       "      <td>-383.0310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>US-2016-108966</td>\n",
       "      <td>2016-10-11</td>\n",
       "      <td>2016-10-18</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>SO-20335</td>\n",
       "      <td>Sean O'Donnell</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>...</td>\n",
       "      <td>33311.0</td>\n",
       "      <td>South</td>\n",
       "      <td>OFF-ST-10000760</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Storage</td>\n",
       "      <td>Eldon Fold 'N Roll Cart System</td>\n",
       "      <td>22.3680</td>\n",
       "      <td>2</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.5164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Row ID        Order ID Order Date  Ship Date       Ship Mode Customer ID  \\\n",
       "0       1  CA-2017-152156 2017-11-08 2017-11-11    Second Class    CG-12520   \n",
       "1       2  CA-2017-152156 2017-11-08 2017-11-11    Second Class    CG-12520   \n",
       "2       3  CA-2017-138688 2017-06-12 2017-06-16    Second Class    DV-13045   \n",
       "3       4  US-2016-108966 2016-10-11 2016-10-18  Standard Class    SO-20335   \n",
       "4       5  US-2016-108966 2016-10-11 2016-10-18  Standard Class    SO-20335   \n",
       "\n",
       "     Customer Name    Segment        Country             City  ...  \\\n",
       "0      Claire Gute   Consumer  United States        Henderson  ...   \n",
       "1      Claire Gute   Consumer  United States        Henderson  ...   \n",
       "2  Darrin Van Huff  Corporate  United States      Los Angeles  ...   \n",
       "3   Sean O'Donnell   Consumer  United States  Fort Lauderdale  ...   \n",
       "4   Sean O'Donnell   Consumer  United States  Fort Lauderdale  ...   \n",
       "\n",
       "  Postal Code  Region       Product ID         Category Sub-Category  \\\n",
       "0     42420.0   South  FUR-BO-10001798        Furniture    Bookcases   \n",
       "1     42420.0   South  FUR-CH-10000454        Furniture       Chairs   \n",
       "2     90036.0    West  OFF-LA-10000240  Office Supplies       Labels   \n",
       "3     33311.0   South  FUR-TA-10000577        Furniture       Tables   \n",
       "4     33311.0   South  OFF-ST-10000760  Office Supplies      Storage   \n",
       "\n",
       "                                        Product Name     Sales  Quantity  \\\n",
       "0                  Bush Somerset Collection Bookcase  261.9600         2   \n",
       "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400         3   \n",
       "2  Self-Adhesive Address Labels for Typewriters b...   14.6200         2   \n",
       "3      Bretford CR4500 Series Slim Rectangular Table  957.5775         5   \n",
       "4                     Eldon Fold 'N Roll Cart System   22.3680         2   \n",
       "\n",
       "   Discount    Profit  \n",
       "0      0.00   41.9136  \n",
       "1      0.00  219.5820  \n",
       "2      0.00    6.8714  \n",
       "3      0.45 -383.0310  \n",
       "4      0.20    2.5164  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:50:31.247606Z",
     "start_time": "2023-10-11T17:50:31.231605Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row ID                    int64\n",
       "Order ID                 object\n",
       "Order Date       datetime64[ns]\n",
       "Ship Date        datetime64[ns]\n",
       "Ship Mode                object\n",
       "Customer ID              object\n",
       "Customer Name            object\n",
       "Segment                  object\n",
       "Country                  object\n",
       "City                     object\n",
       "State                    object\n",
       "Postal Code             float64\n",
       "Region                   object\n",
       "Product ID               object\n",
       "Category                 object\n",
       "Sub-Category             object\n",
       "Product Name             object\n",
       "Sales                   float64\n",
       "Quantity                  int64\n",
       "Discount                float64\n",
       "Profit                  float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:50:39.284606Z",
     "start_time": "2023-10-11T17:50:39.263604Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Office Supplies    6020\n",
       "Furniture          2119\n",
       "Technology         1844\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:50:43.180604Z",
     "start_time": "2023-10-11T17:50:43.154608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Binders        1523\n",
       "Paper          1368\n",
       "Furnishings     957\n",
       "Phones          888\n",
       "Storage         845\n",
       "Art             795\n",
       "Accessories     773\n",
       "Chairs          616\n",
       "Appliances      465\n",
       "Labels          364\n",
       "Tables          319\n",
       "Envelopes       253\n",
       "Bookcases       227\n",
       "Fasteners       217\n",
       "Supplies        190\n",
       "Machines        115\n",
       "Copiers          68\n",
       "Name: Sub-Category, dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales['Sub-Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:50:50.070606Z",
     "start_time": "2023-10-11T17:50:50.052605Z"
    }
   },
   "outputs": [],
   "source": [
    "X_num = sales[['Discount', 'Profit']].columns\n",
    "X_cat = sales[['Category', 'Sub-Category']].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:51:08.506121Z",
     "start_time": "2023-10-11T17:51:08.491122Z"
    }
   },
   "outputs": [],
   "source": [
    "X = sales[['Discount', 'Profit',\n",
    "          'Category', 'Sub-Category']]\n",
    "y = sales['Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T17:51:52.465121Z",
     "start_time": "2023-10-11T17:51:52.438121Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row ID           0\n",
       "Order ID         0\n",
       "Order Date       0\n",
       "Ship Date        0\n",
       "Ship Mode        0\n",
       "Customer ID      0\n",
       "Customer Name    0\n",
       "Segment          0\n",
       "Country          0\n",
       "City             0\n",
       "State            0\n",
       "Postal Code      0\n",
       "Region           0\n",
       "Product ID       0\n",
       "Category         0\n",
       "Sub-Category     0\n",
       "Product Name     0\n",
       "Sales            0\n",
       "Quantity         0\n",
       "Discount         0\n",
       "Profit           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T18:05:52.404416Z",
     "start_time": "2023-10-11T18:05:52.389417Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=15769)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T18:05:53.385420Z",
     "start_time": "2023-10-11T18:05:53.374417Z"
    }
   },
   "outputs": [],
   "source": [
    "# scale and ohe, column\n",
    "\n",
    "num_sub = Pipeline([\n",
    "    ('ss',StandardScaler())\n",
    "])\n",
    "\n",
    "cat_sub = Pipeline([\n",
    "    ('ohe', OneHotEncoder(sparse=False, handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T18:05:54.348418Z",
     "start_time": "2023-10-11T18:05:54.334417Z"
    }
   },
   "outputs": [],
   "source": [
    "CT = ColumnTransformer(transformers=[\n",
    "    ('num',num_sub,X_num),\n",
    "    ('cat',cat_sub,X_cat)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up a Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T18:05:55.323417Z",
     "start_time": "2023-10-11T18:05:55.312417Z"
    }
   },
   "outputs": [],
   "source": [
    "# create stack\n",
    "\n",
    "sr = StackingRegressor(estimators=[\n",
    "    ('lr',LinearRegression()),\n",
    "    ('knn',KNeighborsRegressor()),\n",
    "    ('dt',DecisionTreeRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T18:05:56.353417Z",
     "start_time": "2023-10-11T18:05:56.279415Z"
    }
   },
   "outputs": [],
   "source": [
    "knn_pipe = Pipeline([\n",
    "    ('ct',CT),\n",
    "    ('knn',KNeighborsRegressor())\n",
    "]).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T18:05:57.408415Z",
     "start_time": "2023-10-11T18:05:57.334418Z"
    }
   },
   "outputs": [],
   "source": [
    "dt_pipe = Pipeline([\n",
    "    ('ct',CT),\n",
    "    ('dt',DecisionTreeRegressor())\n",
    "]).fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T18:05:58.418416Z",
     "start_time": "2023-10-11T18:05:58.390416Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_pipe = Pipeline([\n",
    "    ('ct',CT),\n",
    "    ('lr',LinearRegression())\n",
    "]).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T18:05:59.319415Z",
     "start_time": "2023-10-11T18:05:59.310417Z"
    }
   },
   "outputs": [],
   "source": [
    "sr_pipe = Pipeline([\n",
    "    ('ct',CT),\n",
    "    ('sr',sr)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T18:06:01.317874Z",
     "start_time": "2023-10-11T18:06:00.476875Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ct',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('ss',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  Index(['Discount', 'Profit'], dtype='object')),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('ohe',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  Index(['Category', 'Sub-Category'], dtype='object'))])),\n",
       "                ('sr',\n",
       "                 StackingRegressor(estimators=[('lr', LinearRegression()),\n",
       "                                               ('knn', KNeighborsRegressor()),\n",
       "                                               ('dt',\n",
       "                                                DecisionTreeRegressor())]))])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T18:06:05.734875Z",
     "start_time": "2023-10-11T18:06:02.124874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val: [0.59278123 0.82896597 0.83956167 0.848497   0.8719254 ]\n",
      "Median: 0.8395616746102693\n",
      "Mean: 0.7963462549870093\n",
      "Test: 0.6862721427495166\n"
     ]
    }
   ],
   "source": [
    "print_scores(sr_pipe,X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with Base Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T18:06:06.871877Z",
     "start_time": "2023-10-11T18:06:06.639875Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val: [0.12041877 0.50384663 0.50605892 0.22776492 0.44435858]\n",
      "Median: 0.4443585761207117\n",
      "Mean: 0.36048956444700986\n",
      "Test: 0.42639731990949903\n"
     ]
    }
   ],
   "source": [
    "print_scores(lr_pipe, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T18:06:08.392396Z",
     "start_time": "2023-10-11T18:06:07.757392Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val: [0.50081148 0.7605967  0.80378027 0.78971311 0.89178106]\n",
      "Median: 0.7897131088915698\n",
      "Mean: 0.7493365233938197\n",
      "Test: 0.7694785091852561\n"
     ]
    }
   ],
   "source": [
    "print_scores(knn_pipe, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T18:06:09.758391Z",
     "start_time": "2023-10-11T18:06:09.310393Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val: [0.69059898 0.75303755 0.81884449 0.15671231 0.78690672]\n",
      "Median: 0.7530375518894683\n",
      "Mean: 0.6412200079664416\n",
      "Test: 0.07493766699507365\n"
     ]
    }
   ],
   "source": [
    "print_scores(dt_pipe, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "TOC",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
